
CWD =  /home/chengh-wang/Documents/git/BBQ/RPP/RL
/home/chengh-wang/anaconda3/envs/torch-gpu/lib/python3.9/site-packages/gym/envs/registration.py:505: UserWarning: [33mWARN: The environment Ant-v2 is out of date. You should consider upgrading to version `v3` with the environment ID `Ant-v3`.
  logger.warn(
/home/chengh-wang/anaconda3/envs/torch-gpu/lib/python3.9/site-packages/gym/core.py:172: DeprecationWarning: [33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed) instead.
  deprecation(


  1%|â–Œ                                                     | 9954/1000000 [00:04<07:42, 2142.62it/s]/home/chengh-wang/Documents/git/BBQ/RPP/RL/jax_rl/agents/sac_emlp/actor.py:12: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working
  return isinstance(pars, collections.Mapping)







































































































































































































































  7%|â–ˆâ–ˆâ–ˆâ–‹                                                | 70923/1000000 [08:29<1:51:12, 139.23it/s]
Traceback (most recent call last):
  File "/home/chengh-wang/Documents/git/BBQ/RPP/RL/train_emlp_v2.py", line 199, in <module>
    fmt=['%d', '%.1f'])
  File "/home/chengh-wang/anaconda3/envs/torch-gpu/lib/python3.9/site-packages/absl/app.py", line 303, in run
    _run_main(main, args)
  File "/home/chengh-wang/anaconda3/envs/torch-gpu/lib/python3.9/site-packages/absl/app.py", line 251, in _run_main
    sys.exit(main(argv))
  File "/home/chengh-wang/Documents/git/BBQ/RPP/RL/train_emlp_v2.py", line 144, in main
    next_observation, reward, done, info = env.step(action)
  File "/home/chengh-wang/anaconda3/envs/torch-gpu/lib/python3.9/site-packages/gym/core.py", line 314, in step
    observation, reward, done, info = self.env.step(action)
  File "/home/chengh-wang/anaconda3/envs/torch-gpu/lib/python3.9/site-packages/gym/core.py", line 340, in step
    return self.env.step(self.action(action))
  File "/home/chengh-wang/Documents/git/BBQ/RPP/RL/jax_rl/wrappers/episode_monitor.py", line 22, in step
    observation, reward, done, info = self.env.step(action)
  File "/home/chengh-wang/anaconda3/envs/torch-gpu/lib/python3.9/site-packages/gym/wrappers/time_limit.py", line 17, in step
    observation, reward, done, info = self.env.step(action)
  File "/home/chengh-wang/anaconda3/envs/torch-gpu/lib/python3.9/site-packages/gym/wrappers/order_enforcing.py", line 13, in step
    observation, reward, done, info = self.env.step(action)
  File "/home/chengh-wang/anaconda3/envs/torch-gpu/lib/python3.9/site-packages/gym/envs/mujoco/ant.py", line 22, in step
    state = self.state_vector()
  File "/home/chengh-wang/anaconda3/envs/torch-gpu/lib/python3.9/site-packages/gym/envs/mujoco/mujoco_env.py", line 203, in state_vector
    return np.concatenate([self.sim.data.qpos.flat, self.sim.data.qvel.flat])
  File "<__array_function__ internals>", line 180, in concatenate
KeyboardInterrupt