2023-03-25 17:05:15,221 INFO    MainThread:21639 [wandb_setup.py:_flush():76] Configure stats pid to 21639
2023-03-25 17:05:15,221 INFO    MainThread:21639 [wandb_setup.py:_flush():76] Loading settings from /home/chengh-wang/.config/wandb/settings
2023-03-25 17:05:15,221 INFO    MainThread:21639 [wandb_setup.py:_flush():76] Loading settings from /home/chengh-wang/Documents/git/BBQ/RPP/RL/wandb/settings
2023-03-25 17:05:15,221 INFO    MainThread:21639 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
2023-03-25 17:05:15,221 INFO    MainThread:21639 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': 'RPP/RL/train_emlp_v2.py', 'program': '/home/chengh-wang/Documents/git/BBQ/RPP/RL/train_emlp_v2.py'}
2023-03-25 17:05:15,221 INFO    MainThread:21639 [wandb_init.py:_log_setup():461] Logging user logs to /home/chengh-wang/Documents/git/BBQ/RPP/RL/wandb/run-20230325_170515-c4wxiz8l/logs/debug.log
2023-03-25 17:05:15,221 INFO    MainThread:21639 [wandb_init.py:_log_setup():462] Logging internal logs to /home/chengh-wang/Documents/git/BBQ/RPP/RL/wandb/run-20230325_170515-c4wxiz8l/logs/debug-internal.log
2023-03-25 17:05:15,221 INFO    MainThread:21639 [wandb_init.py:init():495] calling init triggers
2023-03-25 17:05:15,222 INFO    MainThread:21639 [wandb_init.py:init():498] wandb.init called with sweep_config: {}
config: {'alsologtostderr': False, 'basic_wd': 1e-06, 'batch_size': 512, 'cbasic_wd': 0.0, 'cequiv_wd': 0.0, 'chex_assert_multiple_cpu_devices': False, 'chex_n_cpu_devices': 1, 'chex_skip_pmap_variant_if_single_device': True, 'clipping': 0.5, 'config': actor_lr: 0.0003
algo: sac
critic_lr: 0.0003
discount: 0.99
hidden_dims: !!python/tuple
- 256
- 256
init_temperature: 1.0
replay_buffer_size: null
target_entropy: null
target_update_period: 1
temp_lr: 0.0003
, 'env_name': 'Ant-v2', 'equiv_wd': 1e-06, 'eval_episodes': 10, 'eval_interval': 10000, 'gan_betas': False, 'group': '', 'hidden_dims': [256, 256], 'log_dir': '', 'log_interval': 1000, 'logger_levels': {}, 'logtostderr': False, 'max_steps': 1000000, 'ncritic': 1, 'old_rep': False, 'only_check_args': False, 'pdb': False, 'pdb_post_mortem': False, 'profile_file': None, 'rpp_policy': True, 'rpp_value': False, 'run_with_pdb': False, 'run_with_profiling': False, 'save_dir': './tmp/', 'save_video': False, 'seed': 42, 'showprefixforinfo': True, 'small_init': True, 'standardize': False, 'start_training': 10000, 'stderrthreshold': 'fatal', 'tau': 0.005, 'test_random_seed': 301, 'test_randomize_ordering_seed': '', 'test_srcdir': '', 'test_tmpdir': '/tmp/absl_testing', 'tqdm': True, 'use_cprofile_for_profiling': True, 'v': -1, 'verbosity': -1, 'xml_output_file': ''}
2023-03-25 17:05:15,222 INFO    MainThread:21639 [wandb_init.py:init():548] starting backend
2023-03-25 17:05:15,222 INFO    MainThread:21639 [backend.py:_multiprocessing_setup():97] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2023-03-25 17:05:15,253 INFO    MainThread:21639 [backend.py:ensure_launched():217] starting backend process...
2023-03-25 17:05:15,275 INFO    MainThread:21639 [backend.py:ensure_launched():222] started backend process with pid: 21862
2023-03-25 17:05:15,277 INFO    MainThread:21639 [wandb_init.py:init():558] backend started and connected
2023-03-25 17:05:15,288 INFO    MainThread:21639 [wandb_init.py:init():634] updated telemetry
2023-03-25 17:05:15,317 INFO    MainThread:21639 [wandb_init.py:init():665] communicating run to backend with 30 second timeout
2023-03-25 17:05:44,408 WARNING MainThread:21639 [wandb_init.py:init():1064] interrupted
Traceback (most recent call last):
  File "/home/chengh-wang/anaconda3/envs/torch-gpu/lib/python3.9/site-packages/wandb/sdk/wandb_init.py", line 1043, in init
    run = wi.init()
  File "/home/chengh-wang/anaconda3/envs/torch-gpu/lib/python3.9/site-packages/wandb/sdk/wandb_init.py", line 668, in init
    run_result = backend.interface.communicate_run(
  File "/home/chengh-wang/anaconda3/envs/torch-gpu/lib/python3.9/site-packages/wandb/sdk/interface/interface.py", line 223, in communicate_run
    return self._communicate_run(run, timeout=timeout)
  File "/home/chengh-wang/anaconda3/envs/torch-gpu/lib/python3.9/site-packages/wandb/sdk/interface/interface_shared.py", line 324, in _communicate_run
    resp = self._communicate(req, timeout=timeout)
  File "/home/chengh-wang/anaconda3/envs/torch-gpu/lib/python3.9/site-packages/wandb/sdk/interface/interface_shared.py", line 226, in _communicate
    return self._communicate_async(rec, local=local).get(timeout=timeout)
  File "/home/chengh-wang/anaconda3/envs/torch-gpu/lib/python3.9/site-packages/wandb/sdk/interface/router.py", line 37, in get
    is_set = self._object_ready.wait(timeout)
  File "/home/chengh-wang/anaconda3/envs/torch-gpu/lib/python3.9/threading.py", line 581, in wait
    signaled = self._cond.wait(timeout)
  File "/home/chengh-wang/anaconda3/envs/torch-gpu/lib/python3.9/threading.py", line 316, in wait
    gotit = waiter.acquire(True, timeout)
KeyboardInterrupt
